<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <meta name="author" content="Hans Pinckaersa*, Shephan Doopera, Geert Litjensa" />
  <title>Introduction</title>
  <style>
    html {
      font-size: 12pt;
      color: #1a1a1a;
      background-color: #fdfdfd;
    }
    body {
      margin: 0 auto;
      max-width: 36em;
      padding-left: 50px;
      padding-right: 50px;
      padding-top: 50px;
      padding-bottom: 50px;
      hyphens: auto;
      overflow-wrap: break-word;
      text-rendering: optimizeLegibility;
      font-kerning: normal;
    }
    @media (max-width: 600px) {
      body {
        font-size: 0.9em;
        padding: 12px;
      }
      h1 {
        font-size: 1.8em;
      }
    }
    @media print {
      html {
        background-color: white;
      }
      body {
        background-color: transparent;
        color: black;
        font-size: 12pt;
      }
      p, h2, h3 {
        orphans: 3;
        widows: 3;
      }
      h2, h3, h4 {
        page-break-after: avoid;
      }
    }
    p {
      margin: 1em 0;
    }
    a {
      color: #1a1a1a;
    }
    a:visited {
      color: #1a1a1a;
    }
    img {
      max-width: 100%;
    }
    h1, h2, h3, h4, h5, h6 {
      margin-top: 1.4em;
    }
    h5, h6 {
      font-size: 1em;
      font-style: italic;
    }
    h6 {
      font-weight: normal;
    }
    ol, ul {
      padding-left: 1.7em;
      margin-top: 1em;
    }
    li > ol, li > ul {
      margin-top: 0;
    }
    blockquote {
      margin: 1em 0 1em 1.7em;
      padding-left: 1em;
      border-left: 2px solid #e6e6e6;
      color: #606060;
    }
    code {
      font-family: Menlo, Monaco, Consolas, 'Lucida Console', monospace;
      font-size: 85%;
      margin: 0;
      hyphens: manual;
    }
    pre {
      margin: 1em 0;
      overflow: auto;
    }
    pre code {
      padding: 0;
      overflow: visible;
      overflow-wrap: normal;
    }
    .sourceCode {
     background-color: transparent;
     overflow: visible;
    }
    hr {
      background-color: #1a1a1a;
      border: none;
      height: 1px;
      margin: 1em 0;
    }
    table {
      margin: 1em 0;
      border-collapse: collapse;
      width: 100%;
      overflow-x: auto;
      display: block;
      font-variant-numeric: lining-nums tabular-nums;
    }
    table caption {
      margin-bottom: 0.75em;
    }
    tbody {
      margin-top: 0.5em;
      border-top: 1px solid #1a1a1a;
      border-bottom: 1px solid #1a1a1a;
    }
    th {
      border-top: 1px solid #1a1a1a;
      padding: 0.25em 0.5em 0.25em 0.5em;
    }
    td {
      padding: 0.125em 0.5em 0.25em 0.5em;
    }
    header {
      margin-bottom: 4em;
      text-align: center;
    }
    #TOC li {
      list-style: none;
    }
    #TOC ul {
      padding-left: 1.3em;
    }
    #TOC > ul {
      padding-left: 0;
    }
    #TOC a:not(:hover) {
      text-decoration: none;
    }
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    /* The extra [class] is a hack that increases specificity enough to
       override a similar rule in reveal.js */
    ul.task-list[class]{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      font-size: inherit;
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
  </style>
  <!--[if lt IE 9]>
    <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv-printshiv.min.js"></script>
  <![endif]-->
</head>
<body>
<header id="title-block-header">
<h1 class="title">Introduction</h1>
<p class="author">Hans Pinckaers<sup>a</sup>*, Shephan
Dooper<sup>a</sup>, Geert Litjens<sup>a</sup></p>
</header>
<p>Corresponding author: Hans Pinckaers, Radboud University Medical
Center, Postbus 9101, 6500 HB Nijmegen, The Netherlands (tel +31 634 856
950, hans.pinckaers@radboudumc.nl)</p>
<p><sup>a</sup> Department of Pathology, Radboud Institute for Health
Sciences, Radboud University Medical Center, Nijmegen, The
Netherlands</p>
<h1 id="introduction">Introduction</h1>
<h3 id="the-data">The data</h3>
<p>At our hospital, we collected a cohort of patient of 903 patients
which underwent prostatectomy, with follow-up information. Primary
endpoint for this cohort was biochemical recurrence. This dataset,
collected by the Urology department recorded biochemical recurrence by
monitoring ordered lab tests of included patients. Patients treated in
the hospital, between 1992 and 2012 were included. These tests were
ordered by treating physicians in the hospital, or outside by general
practitioners. Generally, after one year of follow-up, patients were
transferred to their general practitioner for monitoring.</p>
<p>Tissue slides were picked from the hospital archive containing the
highest grade tumor, based on the pathology reports. Slides were scanned
into whole-slide images on a 3DHistech P1000 scanner, at 0.25mu/px
resolution. The number of slides ranged from 1 to 9 per patient, with a
median of two slides. Before streaming the slides, the tissue on the
slides was combined to create one image with all the tissue. This could
result in multiple gigapixel-sized images.</p>
<!--  pd.read_csv('/Users/Hans/PhD/recurrence/packer/packer_data_file.csv')['name'].value_counts().median() -->
<p><img src="chpt5_imgs/inclusion.png" />
<!-- https://docs.google.com/presentation/d/1JkE6KibsRMDyfYkfxH8U1GhIvSkAnd9PLbyGgmCV5p8/edit#slide=id.p --></p>
<h3 id="experimental-setup">Experimental setup</h3>
<p>We divided this cohort into three sets; a train set, consisting of
257 patients (with 45 biochemical recurrence events), a limited
validation set (110 patients, 19 events) and a hold-out set (296
patients, 52 events). Due to scanner or corrupt whole-slide image files,
we had to exclude an additional four patients.</p>
<p>We leveraged the streaming implementation of chapter 2 to optimize a
imagenet-pretrained ResNet34 with a attention-based regression head,
following Dooper, <em>et al.</em>[cite Stephan Dooper, CLAM]. Between
the regression had and the ResNet34, we reduced the dimensionality of
the feature map with a 4x4 maxpool layer.</p>
<p>We divided the training into two phases. In the first phase, we only
optimized the attention head with the ResNet frozen. During training, we
cropped the images to one gigapixel (32768), to speed up and regularize
the training. We used SGD-momemtum with a learning rate of 3e-6,
streaming tile size 7680, the minitbatch-size was 20. The first phase
converged after 300 epochs. We optimized towards time-to-event following
chapter 4, using the Huber loss.</p>
<p>The second phase started by unfreezing ResNet34. We slightly dropped
the learning rate to 1e-6. The network began overfitting around 10
epochs, we picked the checkpoint at epoch 8 for evaluation. We used
weight averaging of the last five epochs as explained in chapter 3.</p>
<p>Given time constraints, we couldnâ€™t perform further hyperparameter
tuning or experimentation.</p>
<h3 id="results">Results</h3>
<p><img src="chpt5_imgs/results.png" /> <img
src="chpt5_imgs/results_notnormalized.png" /></p>
<p>Univariate Cox proportional hazard analysis, gives a hazard ratio of
1.83 with a p-value of 0.10, with an output range of 0 to 2.6.
Normalizing the range gives a hazard ratio of 4.86. The concordance is
0.6.</p>
<p>TODO: multivariate</p>
<p>Figure 2 shows the concordance of a CoxPH statistical analysis using
the neural network output.</p>
<p><img src="chpt5_imgs/concordance.png" /></p>
<p><img src="chpt5_imgs/heatmap.jpeg" /> <img
src="chpt5_imgs/heatmapwithout.jpeg" /></p>
<h3 id="discussion">Discussion</h3>
<p>This work in progress explored the hypothesis that whole-slide images
can be used to predict prognosis. We analyzed whole-slide images of a
population cohort of patients who had undergone prostatectomy. We
attempted to predict the time to biochemical recurrence for these
patients. Although we could not achieve statistically significant
results due to the size of the dataset, there was a discernible signal
in the slides. Using explainability methods, we demonstrated that the
network focuses on the tumor.</p>
<p>Future work could focus on using survival based losses.</p>
<p>As shown in Figure 2, in agreement with chapter 2, training with a
small dataset of very high-resolution images was remarkably stable.</p>
<p>This preliminary assessment lays the groundwork for fully learning
end-to-end, clinically interesting endpoints from histology images while
harnessing the full potential of neural networks to find relevant
features without manual feature engineering. One could argue that
working on patches adds assumptions to the task and lacks context due to
cropping the slide. However, deep learning has shown that neural
networks can learn these assumptions and signals themselves, given
enough data and appropriate labels.</p>
<!-- Code to train can be found here: /Users/Hans/PhD/pathology-streaming-pipeline/survival -->
<p><strong>Acknowledgments</strong></p>
<p><em>Wouter Bulten</em></p>
<p><strong>References</strong></p>
</body>
</html>
